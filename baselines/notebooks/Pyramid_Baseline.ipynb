{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Pyramid_Baseline.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rGOjKHRg0_S1"
      },
      "source": [
        "# **ACL22 MLC Paper - Pyramid Baseline**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HSjWIUn91CrD"
      },
      "source": [
        "# First, we set up the working environment in google drive. If you are working locally, it will not be necessary but make sure that you are using the GPU.\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R5og6C_01VRp"
      },
      "source": [
        "# We will clone the repositories in the \"MyDrive\" folder.\n",
        "%cd gdrive/MyDrive/"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V8zzKo1f1ZHB"
      },
      "source": [
        "# We create a folder where we will clone each repository. If the folder is already created, then skip this step.\n",
        "!mkdir pyramid-baseline"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L22fYCSk1dxw"
      },
      "source": [
        "# We advance to the folder where we will save the baselines.\n",
        "%cd pyramid-baseline/"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6jgdBKRw1QiE"
      },
      "source": [
        "# Clone the project from the official repository. If you have already cloned it, skip this step.\n",
        "!git clone https://github.com/LorrinWWW/Pyramid.git"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AygyETSu1tqa"
      },
      "source": [
        "%cd Pyramid/"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0ovccc1I1yCe"
      },
      "source": [
        "# We install the repository dependencies.\n",
        "%%capture\n",
        "!pip install gpustat\n",
        "!pip install transformers\n",
        "!pip install sentencepiece\n",
        "!pip install allennlp\n",
        "!pip install flair"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_w08Oggs15H0"
      },
      "source": [
        "# We generate the contextualized embeddings file. Make the necessary changes in the file to generate each combination of contextualized embeddings (flair, bert, bert+flair), and make sure that the delivered JSON files are placed in the requested folder.\n",
        "# Consult the readme to see which model was used to generate the contextualized embeddings.\n",
        "!python runs/gen_bert_flair_emb.py "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NQyNirQw4zVs"
      },
      "source": [
        "# If an error related to storage appears.\n",
        "!pip install --upgrade google-cloud-storage"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6X4WZoX-2mzt"
      },
      "source": [
        "# Train the model, the default settings are for the wl dataset with flair embeddings.\n",
        "# If this error appears: IndexError: index 20000 is out of bounds for dimension 0 with size 20000. Then, after line 121 add: if idx+1==20000: break\n",
        "# If this error appears: RuntimeError: 'lengths' argument should be a 1D CPU int64 tensor, but got 1D cuda:0 Long tensor. Then, use the following line in the 58 line in seqs.py: packed_words = pack_padded_sequence(sorted_seq_tensor, sorted_seq_len.cpu(), True)\n",
        "!python train_ner.py \\\n",
        "        --batch_size 32 \\\n",
        "        --evaluate_interval 500 \\\n",
        "        --dataset wl \\\n",
        "        --pretrained_wv cwlce.txt \\\n",
        "        --max_epoches 500 \\\n",
        "        --model_class PyramidNestNER  \\\n",
        "        --model_write_ckpt output_model \\\n",
        "        --optimizer sgd \\\n",
        "        --lr 0.01 \\\n",
        "        --tag_form iob2  \\\n",
        "        --cased 0 \\\n",
        "        --token_emb_dim 300 \\\n",
        "        --char_emb_dim 30 \\\n",
        "        --char_encoder lstm \\\n",
        "        --lm_emb_dim 4096 \\\n",
        "        --lm_emb_path wl_flair.emb.pkl \\\n",
        "        --tag_vocab_size 100 \\\n",
        "        --vocab_size 20000 \\\n",
        "        --dropout 0.4 \\\n",
        "        --max_depth 16"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3vqEodNc2x2W"
      },
      "source": [
        "!python train_ner.py \\\n",
        "        --batch_size 64 \\\n",
        "        --evaluate_interval 500 \\\n",
        "        --dataset wl \\\n",
        "        --pretrained_wv cwlce.txt  \\\n",
        "        --max_epoches 500 \\\n",
        "        --model_class PyramidNestNER  \\\n",
        "        --model_read_ckpt output_model_path \\\n",
        "        --optimizer sgd \\\n",
        "        --lr 0.01 \\\n",
        "        --tag_form iob2  \\\n",
        "        --token_emb_dim 300 \\\n",
        "        --char_emb_dim 60 \\\n",
        "        --char_encoder lstm \\\n",
        "        --lm_emb_dim 0 \\\n",
        "        --tag_vocab_size 100 \\\n",
        "        --vocab_size 20000 \\\n",
        "        --dropout 0.40 \\\n",
        "        --max_depth 16 \\\n",
        "        --output_filename wl_predictions_file \\\n",
        "        --evaluate 1"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}