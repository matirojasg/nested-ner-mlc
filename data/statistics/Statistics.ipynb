{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "01.-AAAI-Statistics.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "ko1QPi0_YZ8M",
        "BU8Y8qKXeaLk",
        "0PCTix7DYeIm",
        "64BQBXGDYl9D",
        "hU6ye8j7Yoew"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ko1QPi0_YZ8M"
      },
      "source": [
        "# **Simple Yet Powerful: An Overlooked Architecture for Nested Named Entity Recognition - Statistics**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sQUJhm9vcRQM"
      },
      "source": [
        "import numpy as np\n",
        "from collections import defaultdict"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IPiBCoDDbrFX"
      },
      "source": [
        "**Function definitions**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JOEPeACFYYYN"
      },
      "source": [
        "# Function used to read a file in ConLL format. \n",
        "def read_file(path):\n",
        "  f = open(path, 'r', encoding = 'utf-8').read()\n",
        "  sents = [sent for sent in f.split('\\n\\n')]\n",
        "  return sents\n",
        "\n",
        "#Function used to obtain the tokens from the dataset.\n",
        "def get_tokens(sents):\n",
        "  tokens = []\n",
        "  for sent in sents:\n",
        "    for line in sent.splitlines():\n",
        "      tokens.append(line.split()[0])\n",
        "  return tokens\n",
        "\n",
        "# Function used to calculate the average length of entities.\n",
        "def avg_entity_len(entities_per_sentence):\n",
        "  lens = []\n",
        "  for entities in entities_per_sentence:\n",
        "    for entity in entities:\n",
        "      len = entity[2]-entity[1]+1\n",
        "      lens.append(len)\n",
        "  return np.mean(lens)\n",
        "\n",
        "# Function used to calculate the average length of sentences.\n",
        "def avg_sent_len(sents):\n",
        "  lens = [len(sent.splitlines()) for sent in sents]\n",
        "  return np.mean(lens)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4Sfk8dyeDbBu"
      },
      "source": [
        "# Functions taken from the seqeval library, to obtain the dataset's entities in the form of tuples and with the IOB2 format.\n",
        "def get_entities(seq, suffix=False):\n",
        "    \"\"\"Gets entities from sequence.\n",
        "    Args:\n",
        "        seq (list): sequence of labels.\n",
        "    Returns:\n",
        "        list: list of (chunk_type, chunk_start, chunk_end).\n",
        "    Example:\n",
        "        >>> from seqeval.metrics.sequence_labeling import get_entities\n",
        "        >>> seq = ['B-PER', 'I-PER', 'O', 'B-LOC']\n",
        "        >>> get_entities(seq)\n",
        "        [('PER', 0, 1), ('LOC', 3, 3)]\n",
        "    \"\"\"\n",
        "\n",
        "    def _validate_chunk(chunk, suffix):\n",
        "        if chunk in ['O', 'B', 'I', 'E', 'S']:\n",
        "            return\n",
        "\n",
        "        if suffix:\n",
        "            if not chunk.endswith(('-B', '-I', '-E', '-S')):\n",
        "                warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
        "\n",
        "        else:\n",
        "            if not chunk.startswith(('B-', 'I-', 'E-', 'S-')):\n",
        "                warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
        "\n",
        "    # for nested list\n",
        "    if any(isinstance(s, list) for s in seq):\n",
        "        seq = [item for sublist in seq for item in sublist + ['O']]\n",
        "\n",
        "    prev_tag = 'O'\n",
        "    prev_type = ''\n",
        "    begin_offset = 0\n",
        "    chunks = []\n",
        "    for i, chunk in enumerate(seq + ['O']):\n",
        "        _validate_chunk(chunk, suffix)\n",
        "\n",
        "        if suffix:\n",
        "            tag = chunk[-1]\n",
        "            type_ = chunk[:-1].rsplit('-', maxsplit=1)[0] or '_'\n",
        "        else:\n",
        "            tag = chunk[0]\n",
        "            type_ = chunk[1:].split('-', maxsplit=1)[-1] or '_'\n",
        "\n",
        "        if end_of_chunk(prev_tag, tag, prev_type, type_):\n",
        "            chunks.append((prev_type, begin_offset, i - 1))\n",
        "        if start_of_chunk(prev_tag, tag, prev_type, type_):\n",
        "            begin_offset = i\n",
        "        prev_tag = tag\n",
        "        prev_type = type_\n",
        "\n",
        "    return chunks\n",
        "def end_of_chunk(prev_tag, tag, prev_type, type_):\n",
        "    \"\"\"Checks if a chunk ended between the previous and current word.\n",
        "    Args:\n",
        "        prev_tag: previous chunk tag.\n",
        "        tag: current chunk tag.\n",
        "        prev_type: previous type.\n",
        "        type_: current type.\n",
        "    Returns:\n",
        "        chunk_end: boolean.\n",
        "    \"\"\"\n",
        "    chunk_end = False\n",
        "\n",
        "    if prev_tag == 'E':\n",
        "        chunk_end = True\n",
        "    if prev_tag == 'S':\n",
        "        chunk_end = True\n",
        "\n",
        "    if prev_tag == 'B' and tag == 'B':\n",
        "        chunk_end = True\n",
        "    if prev_tag == 'B' and tag == 'S':\n",
        "        chunk_end = True\n",
        "    if prev_tag == 'B' and tag == 'O':\n",
        "        chunk_end = True\n",
        "    if prev_tag == 'I' and tag == 'B':\n",
        "        chunk_end = True\n",
        "    if prev_tag == 'I' and tag == 'S':\n",
        "        chunk_end = True\n",
        "    if prev_tag == 'I' and tag == 'O':\n",
        "        chunk_end = True\n",
        "\n",
        "    if prev_tag != 'O' and prev_tag != '.' and prev_type != type_:\n",
        "        chunk_end = True\n",
        "\n",
        "    return chunk_end\n",
        "\n",
        "def start_of_chunk(prev_tag, tag, prev_type, type_):\n",
        "    \"\"\"Checks if a chunk started between the previous and current word.\n",
        "    Args:\n",
        "        prev_tag: previous chunk tag.\n",
        "        tag: current chunk tag.\n",
        "        prev_type: previous type.\n",
        "        type_: current type.\n",
        "    Returns:\n",
        "        chunk_start: boolean.\n",
        "    \"\"\"\n",
        "    chunk_start = False\n",
        "\n",
        "    if tag == 'B':\n",
        "        chunk_start = True\n",
        "    if tag == 'S':\n",
        "        chunk_start = True\n",
        "\n",
        "    if prev_tag == 'E' and tag == 'E':\n",
        "        chunk_start = True\n",
        "    if prev_tag == 'E' and tag == 'I':\n",
        "        chunk_start = True\n",
        "    if prev_tag == 'S' and tag == 'E':\n",
        "        chunk_start = True\n",
        "    if prev_tag == 'S' and tag == 'I':\n",
        "        chunk_start = True\n",
        "    if prev_tag == 'O' and tag == 'E':\n",
        "        chunk_start = True\n",
        "    if prev_tag == 'O' and tag == 'I':\n",
        "        chunk_start = True\n",
        "\n",
        "    if tag != 'O' and tag != '.' and prev_type != type_:\n",
        "        chunk_start = True\n",
        "\n",
        "    return chunk_start"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uLv7m-Jxc9C8"
      },
      "source": [
        "# Function used to obtain the entities from the lists of sentences.\n",
        "def get_entities_from_multiconll(sents):\n",
        "  entities = []\n",
        "  for sent in sents:\n",
        "    entities_per_level = defaultdict(list)\n",
        "    for line in sent.splitlines():\n",
        "      for i, v in enumerate(line.split()[1:]):\n",
        "        entities_per_level[i].append(v)\n",
        "    \n",
        "    sent_entities = []\n",
        "    for k, v in entities_per_level.items():\n",
        "      sent_entities.extend(get_entities(v))\n",
        "    entities.append(sent_entities)\n",
        "  return entities"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cli7c5otGE33"
      },
      "source": [
        "# Function used to obtain the nested entities from a list of entities.\n",
        "def get_nested_entities(entities_per_sentence):\n",
        "  nested_entities_per_sentence = []\n",
        "  for entities in entities_per_sentence:\n",
        "    nested_entities = []\n",
        "    for e1 in entities:\n",
        "      for e2 in entities:\n",
        "        if e1!=e2:\n",
        "          s_e1 = e1[1]\n",
        "          e_e1 = e1[2]\n",
        "          s_e2 = e2[1]\n",
        "          e_e2 = e2[2]\n",
        "          if (s_e1<=s_e2 and e_e2<=e_e1):\n",
        "            if e1 not in nested_entities:\n",
        "              nested_entities.append(e1)\n",
        "            if e2 not in nested_entities:\n",
        "              nested_entities.append(e2)\n",
        "    nested_entities_per_sentence.append(nested_entities)\n",
        "  return nested_entities_per_sentence"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zMScn4NVAvel"
      },
      "source": [
        "# Function used to obtain complete nestings (internal and external entities).\n",
        "def get_nestings(entities):\n",
        "  nestings = [] \n",
        "  total = []\n",
        "\n",
        "  for e1 in entities:\n",
        "    is_outer = True \n",
        "    possible_nested_entity = [e1]\n",
        "    \n",
        "    for e2 in entities:\n",
        "      if e1!=e2:\n",
        "        s_e1 = e1[1]\n",
        "        e_e1 = e1[2]\n",
        "        s_e2 = e2[1]\n",
        "        e_e2 = e2[2]\n",
        "        if ((s_e1>s_e2 and e_e1<e_e2) or (s_e1==s_e2 and e_e1<e_e2) or (s_e1>s_e2 and e_e1==e_e2)):\n",
        "          is_outer = False \n",
        "        if (s_e2>=s_e1 and e_e2<=e_e1):\n",
        "          if e1 not in total:\n",
        "            total.append(e1)\n",
        "          if e2 not in total:\n",
        "            total.append(e2)\n",
        "          possible_nested_entity.append(e2)\n",
        "    \n",
        "    if len(possible_nested_entity)==1:\n",
        "      is_outer = False\n",
        "    \n",
        "    if is_outer:\n",
        "      possible_nested_entity.sort(key=lambda x: (x[2]-x[1], x[0]), reverse=True)\n",
        "      if possible_nested_entity not in nestings:\n",
        "        nestings.append(possible_nested_entity)\n",
        "  return nestings, total"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M8TjZMTo_R8h"
      },
      "source": [
        "# Functions used to obtain nestings of different types.\n",
        "def is_multilabel_entity(nesting):\n",
        "  for entity in nesting:\n",
        "    if entity[1]!=nesting[0][1] or entity[2]!=nesting[0][2]:\n",
        "      return False\n",
        "  return True\n",
        "\n",
        "def different_nesting_type(true_labels):\n",
        "  support = 0\n",
        "  entities_support = 0\n",
        "  for sent_test_labels in true_labels:\n",
        "    already_added = []\n",
        "    test_nestings, _ = get_nestings(sent_test_labels)\n",
        "    dnt_test = []\n",
        "    for nesting in test_nestings:\n",
        "      if not is_multilabel_entity(nesting):\n",
        "        outer = nesting[0]\n",
        "        dnt = [outer]\n",
        "        for inner in nesting[1:]:\n",
        "          if inner[0]!=outer[0]:\n",
        "            dnt.append(inner)\n",
        "        if len(dnt)>1: dnt_test.append(dnt)\n",
        "    support+=len(dnt_test)\n",
        "    for nest in dnt_test:\n",
        "      for entity in nest:\n",
        "        if entity not in already_added:\n",
        "          entities_support+=1\n",
        "          already_added.append(entity)\n",
        "  return support, entities_support"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3mI81VwA_x3H"
      },
      "source": [
        "# Functions used to obtain nestings of the same type.\n",
        "def same_nesting_type(labels):\n",
        "\n",
        "  support = 0\n",
        "  entities_support = 0\n",
        "  \n",
        "  for true_labels in labels:\n",
        "    test_nestings, tt = get_nestings(true_labels)\n",
        "    already_added = []\n",
        "    snt_test = []\n",
        "    for nesting in test_nestings:\n",
        "      outer = nesting[0]\n",
        "      stn = [outer]\n",
        "      for inner in nesting[1:]:\n",
        "\n",
        "        if inner[0]==outer[0]:\n",
        "          stn.append(inner)\n",
        "\n",
        "      if len(stn)>1: snt_test.append(stn)\n",
        "    \n",
        " \n",
        "    for nest in snt_test:\n",
        "      for entity in nest:\n",
        "        if entity not in already_added:\n",
        "          entities_support+=1\n",
        "          already_added.append(entity)\n",
        "    support+=len(snt_test)\n",
        "\n",
        "  \n",
        "  return support, entities_support"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l2I5b2id_6oK"
      },
      "source": [
        "# Function used to obtain multilabel entities.\n",
        "def multilabel(labels_per_sentence):\n",
        "  nesting_support = 0\n",
        "  entities_support = 0\n",
        "  for true_labels in labels_per_sentence:\n",
        "    already_added = []\n",
        "    test_nestings, tt = get_nestings(true_labels)\n",
        "    test_multilabel_entities = defaultdict(list)\n",
        "    for nesting in test_nestings:\n",
        "      for entity in nesting:\n",
        "        test_multilabel_entities[(entity[1], entity[2])].append(entity[0])\n",
        "    \n",
        "    for k, v in test_multilabel_entities.items():\n",
        "      if len(v)>1:\n",
        "        nesting_support+=1\n",
        "        for val in v:\n",
        "          if (val, k[0], k[1]) not in already_added:\n",
        "            entities_support+=1\n",
        "            already_added.append((val, k[0], k[1]))\n",
        "\n",
        "  return nesting_support, entities_support"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ijh5CZbRZyuG"
      },
      "source": [
        "# Function used to count the entities.\n",
        "def count_entities(entities_per_sentence):\n",
        "  support = 0\n",
        "  for sent in entities_per_sentence:\n",
        "    support+=len(sent)\n",
        "  return support"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BU8Y8qKXeaLk"
      },
      "source": [
        "# **Statistics.**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rZgzHXeBeiQ9"
      },
      "source": [
        "**First, remember to upload the files that are in the zip preprocessed-files.**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0PCTix7DYeIm"
      },
      "source": [
        "**GENIA Statistics.**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K-CbG_cu-CmQ"
      },
      "source": [
        "genia_train_sentences = read_file('genia.train.iob2')[:-1]\n",
        "genia_train_sent_avg = avg_sent_len(genia_train_sentences)\n",
        "genia_train_tokens = get_tokens(genia_train_sentences)\n",
        "genia_train_entities = get_entities_from_multiconll(genia_train_sentences)\n",
        "genia_train_avg = avg_entity_len(genia_train_entities)\n",
        "genia_train_nested_entities = count_entities(get_nested_entities(genia_train_entities))\n",
        "print(f'GENIA train sentences: {len(genia_train_sentences)}')\n",
        "print(f'GENIA train tokens: {len(genia_train_tokens)}')\n",
        "print(f'GENIA train entities: {count_entities((genia_train_entities))}')\n",
        "print(f'GENIA train sentences avg len: {genia_train_sent_avg}')\n",
        "print(f'GENIA train entities avg len: {genia_train_avg}')\n",
        "print(f'GENIA train nested entities: {genia_train_nested_entities}')\n",
        "print(f'GENIA train nesting different type: {different_nesting_type(genia_train_entities)[1]}')\n",
        "print(f'GENIA train nesting same type: {same_nesting_type(genia_train_entities)[1]}')\n",
        "print(f'GENIA train multilabel entities: {multilabel(genia_train_entities)[1]}')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PX6Dbaf9_IRW"
      },
      "source": [
        "genia_test_sentences = read_file('genia.test.iob2')[:-1]\n",
        "genia_test_sent_avg = avg_sent_len(genia_test_sentences)\n",
        "genia_test_tokens = get_tokens(genia_test_sentences)\n",
        "genia_test_entities = get_entities_from_multiconll(genia_test_sentences)\n",
        "genia_test_avg = avg_entity_len(genia_test_entities)\n",
        "genia_test_nested_entities = count_entities(get_nested_entities(genia_test_entities))\n",
        "print(f'GENIA test sentences: {len(genia_test_sentences)}')\n",
        "print(f'GENIA test tokens: {len(genia_test_tokens)}')\n",
        "print(f'GENIA test entities: {count_entities((genia_test_entities))}')\n",
        "print(f'GENIA test sentences avg len: {genia_test_sent_avg}')\n",
        "print(f'GENIA test entities avg len: {genia_test_avg}')\n",
        "print(f'GENIA test nested entities: {genia_test_nested_entities}')\n",
        "print(f'GENIA test nesting different type: {different_nesting_type(genia_test_entities)[1]}')\n",
        "print(f'GENIA test nesting same type: {same_nesting_type(genia_test_entities)[1]}')\n",
        "print(f'GENIA test multilabel entities: {multilabel(genia_test_entities)[1]}')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LGfBa7tyC4u4"
      },
      "source": [
        "genia_dev_sentences = read_file('genia.dev.iob2')[:-1]\n",
        "genia_dev_sent_avg = avg_sent_len(genia_dev_sentences)\n",
        "genia_dev_tokens = get_tokens(genia_dev_sentences)\n",
        "genia_dev_entities = get_entities_from_multiconll(genia_dev_sentences)\n",
        "genia_dev_avg = avg_entity_len(genia_dev_entities)\n",
        "genia_dev_nested_entities = count_entities(get_nested_entities(genia_dev_entities))\n",
        "print(f'GENIA dev sentences: {len(genia_dev_sentences)}')\n",
        "print(f'GENIA dev tokens: {len(genia_dev_tokens)}')\n",
        "print(f'GENIA dev entities: {count_entities((genia_dev_entities))}')\n",
        "print(f'GENIA dev sentences avg len: {genia_dev_sent_avg}')\n",
        "print(f'GENIA dev entities avg len: {genia_dev_avg}')\n",
        "print(f'GENIA dev nested entities: {genia_dev_nested_entities}')\n",
        "print(f'GENIA dev nesting different type: {different_nesting_type(genia_dev_entities)[1]}')\n",
        "print(f'GENIA dev nesting same type: {same_nesting_type(genia_dev_entities)[1]}')\n",
        "print(f'GENIA dev multilabel entities: {multilabel(genia_dev_entities)[1]}')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "64BQBXGDYl9D"
      },
      "source": [
        "**GERMEVAL Statistics.**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ePKdVJsJJWqt"
      },
      "source": [
        "germ_train_sentences = read_file('germ.train.iob2')[:-1]\n",
        "germ_train_sent_avg = avg_sent_len(germ_train_sentences)\n",
        "germ_train_tokens = get_tokens(germ_train_sentences)\n",
        "germ_train_entities = get_entities_from_multiconll(germ_train_sentences)\n",
        "germ_train_avg = avg_entity_len(germ_train_entities)\n",
        "germ_train_nested_entities = count_entities(get_nested_entities(germ_train_entities))\n",
        "print(f'GERM train sentences: {len(germ_train_sentences)}')\n",
        "print(f'GERM train tokens: {len(germ_train_tokens)}')\n",
        "print(f'GERM train entities: {count_entities(germ_train_entities)}')\n",
        "print(f'GERM train sentences avg len: {germ_train_sent_avg}')\n",
        "print(f'GERM train entities avg len: {germ_train_avg}')\n",
        "print(f'GERM train nested entities: {germ_train_nested_entities}')\n",
        "print(f'GERM train nesting different type: {different_nesting_type(germ_train_entities)[1]}')\n",
        "print(f'GERM train nesting same type: {same_nesting_type(germ_train_entities)[1]}')\n",
        "print(f'GERM train multilabel entities: {multilabel(germ_train_entities)[1]}')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1T3wEm6XC7qR"
      },
      "source": [
        "germ_test_sentences = read_file('germ.test.iob2')[:-1]\n",
        "germ_test_sent_avg = avg_sent_len(germ_test_sentences)\n",
        "germ_test_tokens = get_tokens(germ_test_sentences)\n",
        "germ_test_entities = get_entities_from_multiconll(germ_test_sentences)\n",
        "germ_test_avg = avg_entity_len(germ_test_entities)\n",
        "germ_test_nested_entities = count_entities(get_nested_entities(germ_test_entities))\n",
        "print(f'GERM test sentences: {len(germ_test_sentences)}')\n",
        "print(f'GERM test tokens: {len(germ_test_tokens)}')\n",
        "print(f'GERM test entities: {count_entities(germ_test_entities)}')\n",
        "print(f'GERM test sentences avg len: {germ_test_sent_avg}')\n",
        "print(f'GERM test entities avg len: {germ_test_avg}')\n",
        "print(f'GERM test nested entities: {germ_test_nested_entities}')\n",
        "print(f'GERM test nesting different type: {different_nesting_type(germ_test_entities)[1]}')\n",
        "print(f'GERM test nesting same type: {same_nesting_type(germ_test_entities)[1]}')\n",
        "print(f'GERM test multilabel entities: {multilabel(germ_test_entities)[1]}')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OMSMRjERC9Q6"
      },
      "source": [
        "germ_dev_sentences = read_file('germ.dev.iob2')[:-1]\n",
        "germ_dev_sent_avg = avg_sent_len(germ_dev_sentences)\n",
        "germ_dev_tokens = get_tokens(germ_dev_sentences)\n",
        "germ_dev_entities = get_entities_from_multiconll(germ_dev_sentences)\n",
        "germ_dev_avg = avg_entity_len(germ_dev_entities)\n",
        "germ_dev_nested_entities = count_entities(get_nested_entities(germ_dev_entities))\n",
        "print(f'GERM dev sentences: {len(germ_dev_sentences)}')\n",
        "print(f'GERM dev tokens: {len(germ_dev_tokens)}')\n",
        "print(f'GERM dev entities: {count_entities(germ_dev_entities)}')\n",
        "print(f'GERM dev sentences avg len: {germ_dev_sent_avg}')\n",
        "print(f'GERM dev entities avg len: {germ_dev_avg}')\n",
        "print(f'GERM dev nested entities: {germ_dev_nested_entities}')\n",
        "print(f'GERM dev nesting different type: {different_nesting_type(germ_dev_entities)[1]}')\n",
        "print(f'GERM dev nesting same type: {same_nesting_type(germ_dev_entities)[1]}')\n",
        "print(f'GERM dev multilabel entities: {multilabel(germ_dev_entities)[1]}')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hU6ye8j7Yoew"
      },
      "source": [
        "**Chilean Waiting List Statistics.**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A1M4wPpmJYid"
      },
      "source": [
        "wl_train_sentences = read_file('wl.train.iob2')\n",
        "wl_train_sent_avg = avg_sent_len(wl_train_sentences)\n",
        "wl_train_tokens = get_tokens(wl_train_sentences)\n",
        "wl_train_entities = get_entities_from_multiconll(wl_train_sentences)\n",
        "wl_train_avg = avg_entity_len(wl_train_entities)\n",
        "wl_train_nested_entities = count_entities(get_nested_entities(wl_train_entities))\n",
        "print(f'WL train sentences: {len(wl_train_sentences)}')\n",
        "print(f'WL train tokens: {len(wl_train_tokens)}')\n",
        "print(f'WL train entities: {count_entities(wl_train_entities)}')\n",
        "print(f'WL train sentences avg len: {wl_train_sent_avg}')\n",
        "print(f'WL train entities avg len: {wl_train_avg}')\n",
        "print(f'WL train nested entities: {wl_train_nested_entities}')\n",
        "print(f'WL train nesting different type: {different_nesting_type(wl_train_entities)[1]}')\n",
        "print(f'WL train nesting same type: {same_nesting_type(wl_train_entities)[1]}')\n",
        "print(f'WL train multilabel entities: {multilabel(wl_train_entities)[1]}')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qe5ygumhDY-O"
      },
      "source": [
        "wl_test_sentences = read_file('wl.test.iob2')\n",
        "wl_test_sent_avg = avg_sent_len(wl_test_sentences)\n",
        "wl_test_tokens = get_tokens(wl_test_sentences)\n",
        "wl_test_entities = get_entities_from_multiconll(wl_test_sentences)\n",
        "wl_test_avg = avg_entity_len(wl_test_entities)\n",
        "wl_test_nested_entities = count_entities(get_nested_entities(wl_test_entities))\n",
        "print(f'WL test sentences: {len(wl_test_sentences)}')\n",
        "print(f'WL test tokens: {len(wl_test_tokens)}')\n",
        "print(f'WL test entities: {count_entities(wl_test_entities)}')\n",
        "print(f'WL test sentences avg len: {wl_test_sent_avg}')\n",
        "print(f'WL test entities avg len: {wl_test_avg}')\n",
        "print(f'WL test nested entities: {wl_test_nested_entities}')\n",
        "print(f'WL test nesting different type: {different_nesting_type(wl_test_entities)[1]}')\n",
        "print(f'WL test nesting same type: {same_nesting_type(wl_test_entities)[1]}')\n",
        "print(f'WL test multilabel entities: {multilabel(wl_test_entities)[1]}')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J4v8f5tkDaQp"
      },
      "source": [
        "wl_dev_sentences = read_file('wl.dev.iob2')\n",
        "wl_dev_sent_avg = avg_sent_len(wl_dev_sentences)\n",
        "wl_dev_tokens = get_tokens(wl_dev_sentences)\n",
        "wl_dev_entities = get_entities_from_multiconll(wl_dev_sentences)\n",
        "wl_dev_avg = avg_entity_len(wl_dev_entities)\n",
        "wl_dev_nested_entities = count_entities(get_nested_entities(wl_dev_entities)) \n",
        "print(f'WL dev sentences: {len(wl_dev_sentences)}')\n",
        "print(f'WL dev tokens: {len(wl_dev_tokens)}')\n",
        "print(f'WL dev entities: {count_entities(wl_dev_entities)}')\n",
        "print(f'WL dev sentences avg len: {wl_dev_sent_avg}')\n",
        "print(f'WL dev entities avg len: {wl_dev_avg}')\n",
        "print(f'WL dev nested entities: {wl_dev_nested_entities}')\n",
        "print(f'WL dev nesting different type: {different_nesting_type(wl_dev_entities)[1]}')\n",
        "print(f'WL dev nesting same type: {same_nesting_type(wl_dev_entities)[1]}')\n",
        "print(f'WL dev multilabel entities: {multilabel(wl_dev_entities)[1]}')"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}